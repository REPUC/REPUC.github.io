{
    "version": "https://jsonfeed.org/version/1",
    "title": "老王的个人博客 • All posts by \"elk\" category",
    "description": "这是一个 LinuxSre 相关的技术播客",
    "home_page_url": "http://blog.oldwang.site",
    "items": [
        {
            "id": "http://blog.oldwang.site/posts/3825997150.html",
            "url": "http://blog.oldwang.site/posts/3825997150.html",
            "title": "01 ELK 日志收集系统概述",
            "date_published": "2025-12-09T16:00:00.000Z",
            "content_html": "<h1 id=\"elk-相关技术介绍\"><a class=\"anchor\" href=\"#elk-相关技术介绍\">#</a> ELK 相关技术介绍</h1>\n<h2 id=\"1-elk-诞生的背景\"><a class=\"anchor\" href=\"#1-elk-诞生的背景\">#</a> 1. ELK 诞生的背景</h2>\n<h3 id=\"11-没有-elk-分析日志前\"><a class=\"anchor\" href=\"#11-没有-elk-分析日志前\">#</a> 1.1 没有 ELK 分析日志前</h3>\n<p>没有日志分析工具之前，运维工作存在哪些痛点？</p>\n<ul>\n<li>痛点 1：生产出现故障后，运维需要不停的查看各种不同的日志进行分析？是不是毫无头绪？</li>\n<li>痛点 2：项目上线出现错误，如何快速定位问题？如果后端节点过多、日志分散怎么办？</li>\n<li>痛点 3：开发人员需要实时查看日志但又不想给服务器的登陆权限，怎么办？难道每天帮开发取日志？</li>\n<li>痛点 4：如何在海量的日志中快速的提取我们想要的数据？比如：PV、UV、TOP10 的 URL？如果分析的日志数据量大，那么势必会导致查询速度慢、难度增大，最终则会导致我们无法快速的获取到想要的指标。</li>\n<li>痛点 5：CDN 公司需要不停的分析日志，那分析什么？主要分析命中率，为什么？因为我们给用户承诺的命中率是 90% 以上。如果没有达到 90%，我们就要去分析数据为什么没有被命中、为什么没有被缓存下来。</li>\n</ul>\n<h3 id=\"12-使用-elk-分析日志后\"><a class=\"anchor\" href=\"#12-使用-elk-分析日志后\">#</a> 1.2 使用 ELK 分析日志后</h3>\n<p>如上所有的痛点都可以使用日志分析系统 ELK 解决，通过 ELK，将运维所有的服务器日志，业务系统日志都收集到一个平台下，然后提取想要的内容，比如错误信息，警告信息等，当过滤到这种信息，就马上告警，告警后，运维人员就能马上定位是哪台机器、哪个业务系统出现了问题，出现了什么问题。</p>\n<h2 id=\"2-elk-技术栈是什么\"><a class=\"anchor\" href=\"#2-elk-技术栈是什么\">#</a> 2. ELK 技术栈是什么</h2>\n<h3 id=\"21-什么是-elk\"><a class=\"anchor\" href=\"#21-什么是-elk\">#</a> 2.1 什么是 ELK</h3>\n<p>其实 ELK 不是一个单独的技术，而是一套技术的组合，是由 Elasticsearch、Logstash、Kibana 组合而成的。<br />\nELK 是一套开源免费、功能强大的日志分析管理系统。ELK 可以将我们的系统日志、网站日志、应用系统日志等各种日志进行收集、过滤、清洗，然后进行集中存放并可用于实时检索、分析。</p>\n<ul>\n<li>E：Elasticsearch 数据存储；</li>\n<li>L：Logstash 数据采集、数据清洗、数据过滤；</li>\n<li>K：Kibana 数据分析、数据展示；</li>\n</ul>\n<p><strong>缺点</strong>：</p>\n<ul>\n<li>1、Logstash 基于 Java 开发，内存消耗极高</li>\n<li>2、Logstash 与 ElasticSerach 耦合度过紧，容易打爆 ES，造成数据丢失</li>\n</ul>\n<h3 id=\"22-什么是-efk\"><a class=\"anchor\" href=\"#22-什么是-efk\">#</a> 2.2 什么是 EFK</h3>\n<p>简单来说就是将 Logstash 替换成了 Filebeat，那为什么要进行替换？<br />\n因为 Logstash 是基于 JAVA 开发的，在收集日志时会大量的占用业务系统资源，从而影响正常线上业务。而替换成 filebeat 这种较为轻量的日志收集组件，会让业务系统的运行更加的稳定。</p>\n<p><strong>缺点</strong>：</p>\n<ul>\n<li>1、Filebeat 与 ElasticSearch 耦合度过紧，容易打爆 ES，造成数据丢失；</li>\n<li>2、Filebeat 对日志格式的处理与转换，比较的弱；</li>\n</ul>\n<h3 id=\"23-什么是-elfk\"><a class=\"anchor\" href=\"#23-什么是-elfk\">#</a> 2.3 什么是 ELFK</h3>\n<h3 id=\"24-elk-kafka\"><a class=\"anchor\" href=\"#24-elk-kafka\">#</a> 2.4 ELK + Kafka</h3>\n<p>该解决方案可支持每日 1TB 级别的业务日志处理。若贵公司业务日志量达到每日 10 TB，建议根据业务系统进行横向拆分，部署多套独立 ELK 集群。</p>\n<p>Kafka 消息队列 可以将 Filebeat 与 ElasticSearch 进行解耦，从而可以避免 ES 被打爆的现象；</p>\n<p>Logstash</p>\n<ul>\n<li>1、可以从 Kafka 中获取数据，然后匀速写入 ElasticSearch 中：</li>\n<li>2、能针对那些非结构化的数据，将其转为结构化数据，并可以对无用字段进行清洗；</li>\n</ul>\n<h3 id=\"24-efk-收集哪些日志\"><a class=\"anchor\" href=\"#24-efk-收集哪些日志\">#</a> 2.4 EFK 收集哪些日志</h3>\n<ul>\n<li>代理：Haproxy、Nginx</li>\n<li>Web：Nginx、Tomcat、Httpd、PHP</li>\n<li>DB：mysql、redis、mongo、elasticsearch</li>\n<li>存储：nfs、glusterfs、fastdfs</li>\n<li>系统：message、security</li>\n<li>业务：app</li>\n</ul>\n<h3 id=\"25-elk-软件下载地址\"><a class=\"anchor\" href=\"#25-elk-软件下载地址\">#</a> 2.5 ELK 软件下载地址</h3>\n<h4 id=\"251-redhat-系列\"><a class=\"anchor\" href=\"#251-redhat-系列\">#</a> 2.5.1 RedHat 系列</h4>\n<table>\n<thead>\n<tr>\n<th>软件名称</th>\n<th>版本</th>\n<th>下载地址</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ElasticSearch</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.18.2-x86_64.rpm\">https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.18.2-x86_64.rpm</a></td>\n</tr>\n<tr>\n<td>Logstash</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/logstash/logstash-8.18.2-x86_64.rpm\">https://artifacts.elastic.co/downloads/logstash/logstash-8.18.2-x86_64.rpm</a></td>\n</tr>\n<tr>\n<td>Kibana</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/kibana/kibana-8.18.2-x86_64.rpm\">https://artifacts.elastic.co/downloads/kibana/kibana-8.18.2-x86_64.rpm</a></td>\n</tr>\n<tr>\n<td>Filebeat</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.18.2-x86_64.rpm\">https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.18.2-x86_64.rpm</a></td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"252-debian-系统\"><a class=\"anchor\" href=\"#252-debian-系统\">#</a> 2.5.2 Debian 系统</h4>\n<table>\n<thead>\n<tr>\n<th>软件名称</th>\n<th>版本</th>\n<th>下载地址</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ElasticSearch</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.18.2-amd64.deb\">https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.18.2-amd64.deb</a></td>\n</tr>\n<tr>\n<td>Logstash</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/logstash/logstash-8.18.2-amd64.deb\">https://artifacts.elastic.co/downloads/logstash/logstash-8.18.2-amd64.deb</a></td>\n</tr>\n<tr>\n<td>Kibana</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/kibana/kibana-8.18.2-amd64.deb\">https://artifacts.elastic.co/downloads/kibana/kibana-8.18.2-amd64.deb</a></td>\n</tr>\n<tr>\n<td>Filebeat</td>\n<td>8.18.2</td>\n<td><a href=\"https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.18.2-amd64.deb\">https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.18.2-amd64.deb</a></td>\n</tr>\n</tbody>\n</table>\n",
            "tags": [
                "ELK"
            ]
        },
        {
            "id": "http://blog.oldwang.site/posts/4103087246.html",
            "url": "http://blog.oldwang.site/posts/4103087246.html",
            "title": "02 Elasticsearch 入门",
            "date_published": "2025-12-09T16:00:00.000Z",
            "content_html": "<h2 id=\"1、ES-基本概念介绍\"><a href=\"#1、ES-基本概念介绍\" class=\"headerlink\" title=\"1、ES 基本概念介绍\"></a>1、ES 基本概念介绍</h2><h3 id=\"1-1-ES-是什么\"><a href=\"#1-1-ES-是什么\" class=\"headerlink\" title=\"1.1 ES 是什么\"></a>1.1 ES 是什么</h3><p>Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎。</p>\n<h3 id=\"1-2-ES-主要功能\"><a href=\"#1-2-ES-主要功能\" class=\"headerlink\" title=\"1.2 ES 主要功能\"></a>1.2 ES 主要功能</h3><p>数据存储、数据搜索、数据分析。</p>\n<h2 id=\"2、ES-相关术语\"><a href=\"#2、ES-相关术语\" class=\"headerlink\" title=\"2、ES 相关术语\"></a>2、ES 相关术语</h2><h3 id=\"2-1-文档-Document\"><a href=\"#2-1-文档-Document\" class=\"headerlink\" title=\"2.1 文档 Document\"></a>2.1 文档 Document</h3><p>Document 文档就是用户存在 es 中的数据，它是 es 中存储的最小单元。（类似于表中的一行数据）<br><strong>注意</strong>：每个文档都有一个唯一的 ID 表示，可以自行指定，如果不指定 es 会自动生成。</p>\n<h3 id=\"2-2-索引-Index\"><a href=\"#2-2-索引-Index\" class=\"headerlink\" title=\"2.2 索引 Index\"></a>2.2 索引 Index</h3><p>索引其实是一堆文档 Document 的集合。（它类似数据库的中的一个表）<br>在一个索引中，会有多个文档，而每个文档是由多个不同类型的字段拼接在一起的。</p>\n<h3 id=\"2-3-字段-Filed\"><a href=\"#2-3-字段-Filed\" class=\"headerlink\" title=\"2.3 字段 Filed\"></a>2.3 字段 Filed</h3><p>在 ES 中，Document 就是一个 Json Object，一个 Json Object 其实是由多个字段组成的，每个字段它有不同的数据类型。</p>\n<ul>\n<li>字符串：text、keyword。</li>\n<li>数值型：long，integer，short，byte，double，float</li>\n<li>布尔：boolean</li>\n<li>二进制：binary</li>\n<li>范围类型：integer_range，float_range，long_range，double_range，date_range</li>\n</ul>\n<h3 id=\"2-4-ES-术语总结\"><a href=\"#2-4-ES-术语总结\" class=\"headerlink\" title=\"2.4 ES 术语总结\"></a>2.4 ES 术语总结</h3><p>ES 索引、文档、字段关系小结：<br>一个索引里面存储了很多的 Document 文档，一个文档就是一个 Json Object，一个 Json Object 是由多个不同或相同的 filed 字段组成。</p>\n<h2 id=\"3、ES-操作方式\"><a href=\"#3、ES-操作方式\" class=\"headerlink\" title=\"3、ES 操作方式\"></a>3、ES 操作方式</h2><p>ES 的操作和我们传统的数据库操作不太一样，它是通过 Restful API 方式进行操作的，其实本质上就是通过 HTTP 的方式去变更我们的资源状态：</p>\n<ul>\n<li>通过 URI 指定要操作的资源，比如 Index、Document；</li>\n<li>通过 Http Method 指定要操作的方法，如 GET、POST、PUT、DELETE；</li>\n</ul>\n<p>常见操作 ES 的两种方式：Curl、Kibana DevTools</p>\n<h3 id=\"3-1-ES-单节点部署\"><a href=\"#3-1-ES-单节点部署\" class=\"headerlink\" title=\"3.1 ES 单节点部署\"></a>3.1 ES 单节点部署</h3><h4 id=\"3-1-1-CentOS-系列\"><a href=\"#3-1-1-CentOS-系列\" class=\"headerlink\" title=\"3.1.1 CentOS 系列\"></a>3.1.1 CentOS 系列</h4><pre><code class=\"language-bash\"># 1、安装 Java 环境\n[root@es-node1 ~]# yum install java-17-openjdk java-17-openjdk-devel\n\n# 2、安装 ES\n[root@es-node1 ~]# rpm -ivh elasticsearch-8.18.2-x86_64.rpm\n\n# 3、关闭 ES 默认开启的 Security 认证\n[root@es-node1 ~]# vim /etc/elasticsearch/elasticsearch.yml\n# Enable security features\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# 4、修改 ES 的 JVM 堆内存\n[root@es-node1 ~]# vim /etc/elasticsearch/jvm.options\n-Xms1g\n-Xmx1g\n\n# 5、启动 ES 单节点\n[root@es-node1 ~]# systemctl enable --now elasticsearch\n\n# 6. 端口验证\n[root@es-node1 ~]# netstat -nltp\n# 9200    &lt;= HTTP 通信端口\n# 9300    &lt;= 内部集群通信端口\n\n# 7、访问 ES\n[root@es-node1 ~]# curl localhost:9200\n</code></pre>\n<p>访问 ES 正常返回结果：</p>\n<pre><code class=\"language-json\">&#123;\n  &quot;name&quot; : &quot;es-node01.oldwang.net&quot;,\n  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,\n  &quot;cluster_uuid&quot; : &quot;HJlIqvnXQx2KfPzttxcA7A&quot;,\n  &quot;version&quot; : &#123;\n    &quot;number&quot; : &quot;8.18.2&quot;,\n    &quot;build_flavor&quot; : &quot;default&quot;,\n    &quot;build_type&quot; : &quot;rpm&quot;,\n    &quot;build_hash&quot; : &quot;16cc90cd2d08a3147ce02b07e50894bc060a4cbf&quot;,\n    &quot;build_date&quot; : &quot;2099-04-05T14:45:26.420424304Z&quot;,\n    &quot;build_snapshot&quot; : false,\n    &quot;lucene_version&quot; : &quot;9.10.0&quot;,\n    &quot;minimum_wire_compatibility_version&quot; : &quot;7.17.0&quot;,\n    &quot;minimum_index_compatibility_version&quot; : &quot;7.0.0&quot;\n  &#125;,\n  &quot;tagline&quot; : &quot;You Know, for Search&quot;\n&#125;\n</code></pre>\n<h4 id=\"3-1-2-Ubuntu-系列\"><a href=\"#3-1-2-Ubuntu-系列\" class=\"headerlink\" title=\"3.1.2 Ubuntu 系列\"></a>3.1.2 Ubuntu 系列</h4><pre><code class=\"language-bash\"># 1. 安装 Java 环境\n[root@es-node1 ~] apt update\n[root@es-node1 ~] apt install -y openjdk-17-jdk\n\n# 2. 安装 Elasticsearch\n[root@es-node1 ~] wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.18.2-amd64.deb\n[root@es-node1 ~] dpkg -i elasticsearch-8.18.2-amd64.deb\n\n# 3. 关闭 ES 默认开启的 Security 认证\n[root@es-node1 ~] vim /etc/elasticsearch/elasticsearch.yml\n# 修改以下内容\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# 4. 修改 ES 的 JVM 堆内存\n[root@es-node1 ~] vim /etc/elasticsearch/jvm.options\n# 修改\n-Xms1g\n-Xmx1g\n\n# 5. 启动 ES 单节点\n[root@es-node1 ~] systemctl enable --now elasticsearch\n\n# 6. 端口验证\n[root@es-node1 ~] ss -nltp\n# 9200 &lt;= HTTP 通信端口\n# 9300 &lt;= 内部集群通信端口\n\n# 7. 访问 ES\n[root@es-node1 ~] curl localhost:9200\n</code></pre>\n<p>访问 ES 正常返回结果：</p>\n<pre><code class=\"language-json\">&#123;\n  &quot;name&quot; : &quot;es-node1.wang.org&quot;,\n  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,\n  &quot;cluster_uuid&quot; : &quot;xQUmZCMTQ7Ohi3TB25H0Yw&quot;,\n  &quot;version&quot; : &#123;\n    &quot;number&quot; : &quot;8.18.2&quot;,\n    &quot;build_flavor&quot; : &quot;default&quot;,\n    &quot;build_type&quot; : &quot;deb&quot;,\n    &quot;build_hash&quot; : &quot;c6b8d8d951c631db715485edc1a74190cdce4189&quot;,\n    &quot;build_date&quot; : &quot;2025-05-23T10:07:06.210694702Z&quot;,\n    &quot;build_snapshot&quot; : false,\n    &quot;lucene_version&quot; : &quot;9.12.1&quot;,\n    &quot;minimum_wire_compatibility_version&quot; : &quot;7.17.0&quot;,\n    &quot;minimum_index_compatibility_version&quot; : &quot;7.0.0&quot;\n  &#125;,\n  &quot;tagline&quot; : &quot;You Know, for Search&quot;\n&#125;\n</code></pre>\n<h3 id=\"3-2-Curl-命令操作-ES\"><a href=\"#3-2-Curl-命令操作-ES\" class=\"headerlink\" title=\"3.2 Curl 命令操作 ES\"></a>3.2 Curl 命令操作 ES</h3><pre><code class=\"language-bash\"># 1、使用 Curl 命令来创建索引, 录入一份文档\n[root@es-node1 ~]# curl -XPUT &#39;http://localhost:9200/oldwang_index/_doc/1&#39; \\\n-H &quot;Content-Type: application/json&quot; \\\n-d &#39;&#123;\n&quot;name&quot;:&quot;oldwang&quot;,\n&quot;age&quot;:18,\n&quot;salary&quot;: 1000000\n&#125;&#39;\n\n# 2、使用 Curl 命令来查看录入的数据\n[root@es-node1 ~]# curl -XGET &#39;http://localhost:9200/oldwang_index/_doc/1&#39;\n</code></pre>\n<p>查看数据返回结果：</p>\n<pre><code class=\"language-json\">&#123;&quot;_index&quot;:&quot;oldwang_index&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;_seq_no&quot;:0,&quot;_primary_term&quot;:1,&quot;found&quot;:true,&quot;_source&quot;:&#123;\n  &quot;username&quot;: &quot;oldwang&quot;,\n  &quot;age&quot;: 18,\n  &quot;salary&quot;: 1000000\n&#125;&#125;\n</code></pre>\n<h3 id=\"3-3-安装-Kibana-操作-ES\"><a href=\"#3-3-安装-Kibana-操作-ES\" class=\"headerlink\" title=\"3.3 安装 Kibana 操作 ES\"></a>3.3 安装 Kibana 操作 ES</h3><h4 id=\"3-3-1-CentOS-系列\"><a href=\"#3-3-1-CentOS-系列\" class=\"headerlink\" title=\"3.3.1 CentOS 系列\"></a>3.3.1 CentOS 系列</h4><pre><code class=\"language-bash\"># 1、安装 kibana\n[root@es-node1 ~]# rpm -ivh kibana-8.18.2-x86_64.rpm\n\n# 2、配置 Kibana\n[root@es-node1 ~]# vim /etc/kibana/kibana.yml\n# 配置内容：\nserver.port: 5601                                  # kibana 默认监听端口\nserver.host: &quot;0.0.0.0&quot;                             # kibana 监听地址段\nserver.name: &quot;kibana-node&quot;                         # kibana 实例名称\nserver.publicBaseUrl: &quot;http://kibana.oldwang.net&quot;    # Kibana 的公共 URL, 例如分享链接、API 调用等都会使用该地址\nelasticsearch.hosts: [&quot;http://localhost:9200&quot;]     # kibana 从 coordinating 节点获取数据(此处 ES. Kibana 属同节点, 因此填写 localhost; 正常应该填写 ES 服务器地址)\ni18n.locale: &quot;zh-CN&quot;                               # kibana 汉化\n\n# 3、启动 kibana\n[root@es-node1 ~]# systemctl enable kibana --now\n</code></pre>\n<h4 id=\"3-3-2-Ubuntu-系列\"><a href=\"#3-3-2-Ubuntu-系列\" class=\"headerlink\" title=\"3.3.2 Ubuntu 系列\"></a>3.3.2 Ubuntu 系列</h4><pre><code class=\"language-bash\"># 1、安装 kibana\n[root@kibana ~]# dpkg -i kibana-8.18.2-amd64.deb\n\n# 2、配置 Kibana\n[root@kibana ~]# vim /etc/kibana/kibana.yml\n# 配置内容：\nserver.port: 5601                                  # kibana 默认监听端口\nserver.host: &quot;0.0.0.0&quot;                             # kibana 监听地址段\nserver.name: &quot;kibana-node&quot;                         # kibana 实例名称\nserver.publicBaseUrl: &quot;http://192.168.80.150&quot;      # Kibana 的公共 URL, 例如分享链接、API 调用等都会使用该地址 (推荐使用域名地址)\nelasticsearch.hosts: [&quot;http://192.168.80.151:9200&quot;] # 此处填写 ES 服务器地址, kibana 从 coordinating 节点获取数据\ni18n.locale: &quot;zh-CN&quot;                               # kibana 汉化\n\n# 3、启动 kibana\n[root@kibana ~]# systemctl enable kibana --now\n</code></pre>\n<h3 id=\"3-4-访问-Kibana\"><a href=\"#3-4-访问-Kibana\" class=\"headerlink\" title=\"3.4 访问 Kibana\"></a>3.4 访问 Kibana</h3><p>访问地址：<code>http://192.168.80.150:5601</code></p>\n<h3 id=\"3-5-启用堆栈监测（或-安装-Metricbeat-实现）\"><a href=\"#3-5-启用堆栈监测（或-安装-Metricbeat-实现）\" class=\"headerlink\" title=\"3.5 启用堆栈监测（或 安装 Metricbeat 实现）\"></a>3.5 启用堆栈监测（或 安装 Metricbeat 实现）</h3><p>操作路径：<code>Management &gt; 堆栈监测 &gt; 使用内部收集设置 &gt; 打开 Monitoring</code></p>\n<h2 id=\"4、索引-API\"><a href=\"#4、索引-API\" class=\"headerlink\" title=\"4、索引 API\"></a>4、索引 API</h2><p>ES 有专门的 Index API，用于创建、更新、删除索引配置等。<br>操作入口：<code>Management &gt; 开发工具</code></p>\n<h3 id=\"4-1-创建索引\"><a href=\"#4-1-创建索引\" class=\"headerlink\" title=\"4.1 创建索引\"></a>4.1 创建索引</h3><p>创建索引相关 API：</p>\n<pre><code class=\"language-bash\"># 创建索引\nPUT /oldwang_index\n\n# 查看所有已存在的索引\nGET _cat/indices\n\n# 查看健康状态\nGET _cat/health\n\n# 查看节点主机\nGET _cat/nodes\n</code></pre>\n<p>使用方式：在 Kibana 开发工具中输入需要运行的命令，单击运行发送请求。</p>\n<h3 id=\"4-2-删除索引\"><a href=\"#4-2-删除索引\" class=\"headerlink\" title=\"4.2 删除索引\"></a>4.2 删除索引</h3><p>删除索引 API：</p>\n<pre><code class=\"language-bash\"># 删除索引\nDELETE /oldwang_index\n</code></pre>\n<h3 id=\"4-3-查看索引\"><a href=\"#4-3-查看索引\" class=\"headerlink\" title=\"4.3 查看索引\"></a>4.3 查看索引</h3><p>使用 Kibana 查看索引路径：<code>Stack Management &gt; 索引管理 &gt; 索引</code></p>\n<h2 id=\"5、文档-API\"><a href=\"#5、文档-API\" class=\"headerlink\" title=\"5、文档 API\"></a>5、文档 API</h2><p>ES 为索引添加文档，有专门的 Document API：</p>\n<ul>\n<li>创建文档</li>\n<li>查询文档</li>\n<li>更新文档</li>\n<li>删除文档</li>\n</ul>\n<h3 id=\"5-1-创建文档\"><a href=\"#5-1-创建文档\" class=\"headerlink\" title=\"5.1 创建文档\"></a>5.1 创建文档</h3><h4 id=\"创建文档（指定-ID）\"><a href=\"#创建文档（指定-ID）\" class=\"headerlink\" title=\"创建文档（指定 ID）\"></a>创建文档（指定 ID）</h4><pre><code class=\"language-bash\"># 创建一个文档 (指定ID)\nPOST /oldwang_index/_doc/1\n&#123;\n  &quot;username&quot;: &quot;oldwang&quot;,\n  &quot;age&quot;: 18,\n  &quot;salary&quot;: 1000000\n&#125;\n</code></pre>\n<p><strong>说明</strong>：创建文档时，如果索引不存在，ES 会自动创建对应的 index 和 type。</p>\n<h4 id=\"创建文档（不指定-ID）\"><a href=\"#创建文档（不指定-ID）\" class=\"headerlink\" title=\"创建文档（不指定 ID）\"></a>创建文档（不指定 ID）</h4><pre><code class=\"language-bash\"># 创建文档，不指定 ID（id 会生成随机字符串）\nPOST /oldwang_index/_doc\n&#123;\n  &quot;username&quot;: &quot;oldwang&quot;,\n  &quot;age&quot;: 18,\n  &quot;salary&quot;: 1000000\n&#125;\n</code></pre>\n<h3 id=\"5-2-查询文档\"><a href=\"#5-2-查询文档\" class=\"headerlink\" title=\"5.2 查询文档\"></a>5.2 查询文档</h3><h4 id=\"查询指定-ID-文档\"><a href=\"#查询指定-ID-文档\" class=\"headerlink\" title=\"查询指定 ID 文档\"></a>查询指定 ID 文档</h4><pre><code class=\"language-bash\">GET /oldwang_index/_doc/1\n</code></pre>\n<h4 id=\"查询所有文档\"><a href=\"#查询所有文档\" class=\"headerlink\" title=\"查询所有文档\"></a>查询所有文档</h4><pre><code class=\"language-bash\">GET /oldwang_index/_search\n</code></pre>\n<h4 id=\"查询指定内容\"><a href=\"#查询指定内容\" class=\"headerlink\" title=\"查询指定内容\"></a>查询指定内容</h4><pre><code class=\"language-bash\">GET /oldwang_index/_search\n&#123;\n  &quot;query&quot;: &#123;\n    &quot;match&quot;: &#123;\n      &quot;username&quot;: &quot;oldwang&quot;    \n    &#125;\n  &#125;\n&#125;\n</code></pre>\n<h3 id=\"5-3-批量创建文档\"><a href=\"#5-3-批量创建文档\" class=\"headerlink\" title=\"5.3 批量创建文档\"></a>5.3 批量创建文档</h3><p>ES 允许通过 <code>_bulk</code> 一次创建多个文档，从而减少网络传输开销，提升写入速率。</p>\n<pre><code class=\"language-bash\"># 批量创建 Document\nPOST _bulk\n&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;tt&quot;,&quot;_id&quot;:&quot;1&quot;&#125;&#125;\n&#123;&quot;name&quot;:&quot;oldwang&quot;,&quot;age&quot;:&quot;18&quot;&#125;\n&#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;tt&quot;,&quot;_id&quot;:&quot;2&quot;&#125;&#125;\n&#123;&quot;name&quot;:&quot;oldqiang&quot;,&quot;age&quot;:&quot;30&quot;&#125;\n&#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;tt&quot;,&quot;_id&quot;:&quot;2&quot;&#125;&#125;\n&#123;&quot;update&quot;:&#123;&quot;_id&quot;:&quot;1&quot;,&quot;_index&quot;:&quot;tt&quot;&#125;&#125;\n&#123;&quot;doc&quot;:&#123;&quot;age&quot;:&quot;20&quot;&#125;&#125;\n</code></pre>\n<h3 id=\"5-4-批量查询文档\"><a href=\"#5-4-批量查询文档\" class=\"headerlink\" title=\"5.4 批量查询文档\"></a>5.4 批量查询文档</h3><p>ES 允许通过 <code>_mget</code> 一次查询多个文档。</p>\n<pre><code class=\"language-bash\"># 批量查询 Document\nGET _mget\n&#123;\n  &quot;docs&quot;: [\n    &#123;\n      &quot;_index&quot;: &quot;tt&quot;,\n      &quot;_id&quot;: &quot;1&quot;\n    &#125;,\n    &#123;\n      &quot;_index&quot;: &quot;tt&quot;,\n      &quot;_id&quot;: &quot;2&quot;\n    &#125;\n  ]\n&#125;\n</code></pre>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>ES 核心概念：文档是最小存储单元（对应数据库行）、索引是文档集合（对应数据库表）、字段是文档的属性且有多种数据类型。</li>\n<li>ES 操作核心：基于 RESTful API，可通过 Curl 命令行或 Kibana 可视化工具操作，核心 HTTP 方法包括 PUT&#x2F;GET&#x2F;POST&#x2F;DELETE。</li>\n<li>部署与使用：CentOS&#x2F;Ubuntu 系统均支持 ES 和 Kibana 部署，Kibana 可汉化且提供友好的可视化操作界面，支持索引和文档的增删改查及批量操作。</li>\n</ol>\n",
            "tags": [
                "ELK"
            ]
        },
        {
            "id": "http://blog.oldwang.site/posts/3192084428.html",
            "url": "http://blog.oldwang.site/posts/3192084428.html",
            "title": "03 Elasticsearch 集群",
            "date_published": "2025-12-09T16:00:00.000Z",
            "content_html": "<h2 id=\"1、ElasticSearch-集群\"><a href=\"#1、ElasticSearch-集群\" class=\"headerlink\" title=\"1、ElasticSearch 集群\"></a>1、ElasticSearch 集群</h2><h3 id=\"1-1-ES-集群优势\"><a href=\"#1-1-ES-集群优势\" class=\"headerlink\" title=\"1.1 ES 集群优势\"></a>1.1 ES 集群优势</h3><p>Elasticsearch 集群是由多个节点组成的一个分布式系统。<br>使用 Elasticsearch 集群有以下几个优点：</p>\n<ol>\n<li><strong>扩展性</strong>：Elasticsearch 集群将数据分布在多个节点，也就是可以使用更多的 CPU、内存、磁盘等。从而能够进行大规模的数据存储和处理工作。随着数据不断的增长，可以通过向集群添加更多的节点来应对。这样即使数据量达到 PB 级别，Elasticsearch 集群仍可以正常工作。<br>场景说明：应用程序每天生成数百万条日志。单个服务器可能很快就会被数据量压垮。使用 Elasticsearch 集群后，就可以将数据均匀分布到多个节点上，这样每个节点只需要负责处理一部分的数据，从而实现整体的扩展性，以应对大规模的数据增长。</li>\n<li><strong>数据的容灾</strong>：Elasticsearch 集群通过在多个节点上存储数据的副本，来实现数据的容灾。意味着，如果某个节点发生故障，数据仍然可以从其他节点的副本中快速恢复，无需人工干预，从而减少了业务中断的风险。从而保证了整个集群的正常运行。</li>\n<li><strong>服务的高可用性</strong>：Elasticsearch 集群具有自动检测节点故障的能力。当某个节点发生故障时，集群会将故障节点上的任务快速分配给其他正常运行的节点。这样，即使某个节点发生故障，整个集群仍可以继续正常运行。（用户几乎感觉不到任何影响。）</li>\n</ol>\n<h3 id=\"1-2-ES-如何组集群\"><a href=\"#1-2-ES-如何组集群\" class=\"headerlink\" title=\"1.2 ES 如何组集群\"></a>1.2 ES 如何组集群</h3><ol>\n<li><p>单节点 ES，如下图所示；</p>\n</li>\n<li><p>如果单节点出现问题，服务就不可用了，新增一个 ES 节点加入集群</p>\n</li>\n</ol>\n<p>Elasticsearch 集群是由多个节点组成的，通过 <code>cluster.name</code> 定义集群名称，然后每个节点通过 <code>node.name</code> 来标识在集群中的名称。<br><code>cluster.name</code> 相同则表示隶属于同一个集群。</p>\n<h2 id=\"2、ES-集群环境部署\"><a href=\"#2、ES-集群环境部署\" class=\"headerlink\" title=\"2、ES 集群环境部署\"></a>2、ES 集群环境部署</h2><h3 id=\"2-0-环境地址规划\"><a href=\"#2-0-环境地址规划\" class=\"headerlink\" title=\"2.0 环境地址规划\"></a>2.0 环境地址规划</h3><table>\n<thead>\n<tr>\n<th>系统版本</th>\n<th>主机名称</th>\n<th>IP 地址</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RockyLinux9 | Ubuntu2204</td>\n<td>kibana.wang.org</td>\n<td>192.168.80.150</td>\n</tr>\n<tr>\n<td>RockyLinux9 | Ubuntu2204</td>\n<td>es-node1.wang.org</td>\n<td>192.168.80.151</td>\n</tr>\n<tr>\n<td>RockyLinux9 | Ubuntu2204</td>\n<td>es-node2.wang.org</td>\n<td>192.168.80.152</td>\n</tr>\n<tr>\n<td>RockyLinux9 | Ubuntu2204</td>\n<td>es-node3.wang.org</td>\n<td>192.168.80.153</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-1-node1-集群节点配置\"><a href=\"#2-1-node1-集群节点配置\" class=\"headerlink\" title=\"2.1 node1 集群节点配置\"></a>2.1 node1 集群节点配置</h3><pre><code class=\"language-bash\"># 1、安装 elasticSearch\n[root@es-node1 ~]# yum install java-17-openjdk java-17-openjdk-devel -y\n[root@es-node1 ~]# rpm -ivh elasticsearch-8.18.2-x86_64.rpm\n[root@es-node1 ~]$ dpkg -i elasticsearch-8.18.2-amd64.deb\n\n# 2、配置 elasticSearch\n[root@es-node1 ~]# vim /etc/elasticsearch/elasticsearch.yml\ncluster.name: es-cluster                # 集群名称\nnode.name: es-node1                     # 节点名称\npath.data: /var/lib/elasticsearch       # 数据存储路径\npath.logs: /var/log/elasticsearch       # 日志存储路径\n# bootstrap.memory_lock: true           # 内存锁定，避免 es 使用 swap\nnetwork.host: 192.168.80.151            # 本机 IP 地址, 监听在本地哪个地址上\nhttp.port: 9200                         # 监听端口\ndiscovery.seed_hosts: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]  # 集群主机列表\ncluster.initial_master_nodes: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]  # 参与选举的主机, 仅第一次启动集群时进行选举 [可以填写 node.name 的名称]\n# 注释如下行重复配置 [重要]\n# cluster.initial_master_nodes: [&quot;es-node1.wang.org&quot;]\n\n# 关闭 Security\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# 3. 配置 JVM 内存\n[root@es-node1 ~]# vim /etc/elasticsearch/jvm.options\n-Xms512m\n-Xmx512m\n\n# 4. 重启 ES 服务\n[root@es-node1 ~]# rm -rf /var/log/elasticsearch/*\n[root@es-node1 ~]# systemctl restart elasticsearch\n[root@es-node1 ~]# systemctl enable --now elasticsearch\n</code></pre>\n<h3 id=\"2-2-node2-集群节点配置\"><a href=\"#2-2-node2-集群节点配置\" class=\"headerlink\" title=\"2.2 node2 集群节点配置\"></a>2.2 node2 集群节点配置</h3><pre><code class=\"language-bash\"># 1、安装 elasticSearch\n[root@es-node2 ~]# yum install java-17-openjdk java-17-openjdk-devel -y\n[root@es-node2 ~]# rpm -ivh elasticsearch-8.18.2-x86_64.rpm\n[root@es-node2 ~]$ dpkg -i elasticsearch-8.18.2-amd64.deb\n\n# 2、配置 elasticSearch\n[root@es-node2 ~]# vim /etc/elasticsearch/elasticsearch.yml\ncluster.name: es-cluster\nnode.name: es-node2\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 192.168.80.152            # 本机 IP 地址\ndiscovery.seed_hosts: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]\ncluster.initial_master_nodes: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]\n# 注释如下行重复配置 [重要]\n# cluster.initial_master_nodes: [&quot;es-node2.wang.org&quot;]\n\n# 关闭 Security\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# 3. 配置 JVM 内存\n[root@es-node2 ~]# vim /etc/elasticsearch/jvm.options\n-Xms512m\n-Xmx512m\n\n# 4. 重启 ES 服务\n[root@es-node2 ~]# rm -rf /var/log/elasticsearch/*\n[root@es-node2 ~]# systemctl restart elasticsearch\n[root@es-node2 ~]# systemctl enable --now elasticsearch\n</code></pre>\n<h3 id=\"2-3-node3-集群节点配置\"><a href=\"#2-3-node3-集群节点配置\" class=\"headerlink\" title=\"2.3 node3 集群节点配置\"></a>2.3 node3 集群节点配置</h3><pre><code class=\"language-bash\"># 1、安装 elasticSearch\n[root@es-node3 ~]# yum install java-17-openjdk java-17-openjdk-devel -y\n[root@es-node3 ~]# rpm -ivh elasticsearch-8.18.2-x86_64.rpm\n[root@es-node3 ~]$ dpkg -i elasticsearch-8.18.2-amd64.deb\n\n# 2、配置 elasticSearch\n[root@es-node3 ~]# vim /etc/elasticsearch/elasticsearch.yml\ncluster.name: es-cluster\nnode.name: es-node3\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 192.168.80.153        # 本机 IP 地址\ndiscovery.seed_hosts: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]\ncluster.initial_master_nodes: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]\n\n# 注释如下行重复配置 [重要]\n# cluster.initial_master_nodes: [&quot;es-node3.wang.org&quot;]\n\n# 关闭 Security\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# 3. 配置 JVM 内存\n[root@es-node3 ~]# vim /etc/elasticsearch/jvm.options\n-Xms512m\n-Xmx512m\n\n# 4. 重启 ES 服务\n[root@es-node3 ~]# rm -rf /var/log/elasticsearch/*\n[root@es-node3 ~]# systemctl restart elasticsearch\n[root@es-node3 ~]# systemctl enable --now elasticsearch\n</code></pre>\n<h2 id=\"3、ES-集群状态检测\"><a href=\"#3、ES-集群状态检测\" class=\"headerlink\" title=\"3、ES 集群状态检测\"></a>3、ES 集群状态检测</h2><h3 id=\"3-1-ES-集群指标状态\"><a href=\"#3-1-ES-集群指标状态\" class=\"headerlink\" title=\"3.1 ES 集群指标状态\"></a>3.1 ES 集群指标状态</h3><p><code>Cluster Health</code> 获取集群的健康状态，整个集群状态包括以下三种：</p>\n<ol>\n<li><strong>green</strong>：健康状态，指所有主副分片都正常分配</li>\n<li><strong>yellow</strong>：所有主分片都正常分配，但是有副本分片未正常分配</li>\n<li><strong>red</strong>：有主分片未分配，也就是索引不完备，写可能有问题。（但不代表不能读取数据）</li>\n</ol>\n<p>检查 ES 集群是否正常运行，可以通过 curl、Cerebro 两种方式。</p>\n<pre><code class=\"language-bash\">curl http://127.0.0.1:9200/_cat/health\ncurl http://127.0.0.1:9200/_cat/nodes?v\n</code></pre>\n<h3 id=\"3-2-Curl-命令检查集群状态\"><a href=\"#3-2-Curl-命令检查集群状态\" class=\"headerlink\" title=\"3.2 Curl 命令检查集群状态\"></a>3.2 Curl 命令检查集群状态</h3><pre><code class=\"language-bash\"># 1、使用 curl 工具检查 ES 集群状态\n[root@es-node3 ~]# curl http://192.168.80.151:9200/_cluster/health?pretty=true\n&#123;\n  &quot;cluster_name&quot; : &quot;es-cluster&quot;,\n  &quot;status&quot; : &quot;green&quot;,\n  &quot;timed_out&quot; : false,\n  &quot;number_of_nodes&quot; : 3,\n  &quot;number_of_data_nodes&quot; : 3,\n  &quot;active_primary_shards&quot; : 36,\n  &quot;active_shards&quot; : 72,\n  &quot;relocating_shards&quot; : 0,\n  &quot;initializing_shards&quot; : 0,\n  &quot;unassigned_shards&quot; : 0,\n  &quot;unassigned_primary_shards&quot; : 0,\n  &quot;delayed_unassigned_shards&quot; : 0,\n  &quot;number_of_pending_tasks&quot; : 0,\n  &quot;number_of_in_flight_fetch&quot; : 0,\n  &quot;task_max_waiting_in_queue_millis&quot; : 0,\n  &quot;active_shards_percent_as_number&quot; : 100.0\n&#125;\n\n# 2、也可以编写脚本监控 ES 集群状态\ncurl -s http://192.168.80.151:9200/_cluster/health?pretty=true | grep &quot;status&quot; | awk -F &#39;&quot;&#39; &#39;&#123;print $4&#125;&#39;\n# 输出: green\n</code></pre>\n<h3 id=\"3-3-安装-Cerebro-检查集群状态\"><a href=\"#3-3-安装-Cerebro-检查集群状态\" class=\"headerlink\" title=\"3.3 安装 Cerebro 检查集群状态\"></a>3.3 安装 Cerebro 检查集群状态</h3><p>cerebro 是可视化工具，用于检查 ES 集群状态。</p>\n<h4 id=\"RockyLinux9-部署-Cerebro\"><a href=\"#RockyLinux9-部署-Cerebro\" class=\"headerlink\" title=\"RockyLinux9 部署 Cerebro\"></a>RockyLinux9 部署 Cerebro</h4><pre><code class=\"language-bash\"># 1、安装 java, 它目前仅支持 java1.8 版本\n# 并不支持较高的 java 版本, &quot;因此不要与 ES 安装在同一节点上&quot;\n[root@kibana ~]# yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel -y\n\n# 2、安装 Cerebro\n[root@kibana ~]# wget https://github.com/lmenezes/cerebro/releases/download/v0.9.4/cerebro-0.9.4-1.noarch.rpm\n[root@kibana ~]# rpm -ivh cerebro-0.9.4-1.noarch.rpm\n\n# 3、配置 Cerebro\n[root@kibana ~]# vim /etc/cerebro/application.conf\ndata.path: &quot;/var/lib/cerebro/cerebro.db&quot;\n# data.path = &quot;./cerebro.db&quot;\n\n# 4、启动 Cerebro\n[root@kibana ~]# systemctl start cerebro\n\n# 查看端口\n[root@kibana ~]# netstat -lntp\nProto Recv-Q Send-Q Local Address   Foreign Address     State       PID/Program name\ntcp6       0      0 :::9000         :::*                LISTEN     504/java\n</code></pre>\n<h4 id=\"Ubuntu2204-部署-Cerebro\"><a href=\"#Ubuntu2204-部署-Cerebro\" class=\"headerlink\" title=\"Ubuntu2204 部署 Cerebro\"></a>Ubuntu2204 部署 Cerebro</h4><pre><code class=\"language-bash\"># 可以将其安装在 Kibana 主机\n# 依赖 JDK-11\n[root@ubuntu2204 ~]# apt -y install openjdk-11-jdk\n\n# 下载包, 官方提供了 DEB 和 RPM 包\n[root@ubuntu2204 ~]# wget https://github.com/lmenezes/cerebro/releases/download/v0.9.4/cerebro_0.9.4_all.deb\n\n# 安装\n[root@ubuntu2204 ~]# dpkg -i cerebro_0.9.4_all.deb\n\n# 启动\n[root@ubuntu2204 ~]# systemctl start cerebro.service\n\n# 默认服务无法启动, 端口无法打开\n[root@ubuntu2204 ~]# ss -ntlp | grep 9000\n\n# 默认无法启动, 查看日志, 可以看到以下提示, 原因是默认 cerebro.db 文件所有目录没有权限导致\n[root@ubuntu2204 ~]# journalctl -u cerebro\n# 报错: Caused by: java.sql.SQLException: opening db: &#39;./cerebro.db&#39;: 权限不够\n\n# 修改配置文件\n[root@ubuntu2204 ~]# vim /etc/cerebro/application.conf\ndata.path: &quot;/var/lib/cerebro/cerebro.db&quot;  # 取消此行注释\n# data.path = &quot;./cerebro.db&quot;              # 注释此行, 默认路径是 /usr/share/cerebro/cerebro.db\n\n# 此目录自动生成\n[root@ubuntu2204 ~]# ll -d /var/lib/cerebro\ndrwxr-xr-x 2 cerebro cerebro 4096   4月 10     2021 /var/lib/cerebro/\n\n# 重启服务\n[root@ubuntu2204 ~]# systemctl restart cerebro.service\n[root@ubuntu2204 ~]# systemctl enable --now cerebro.service\n\n# 默认监听 9000 端口\n[root@ubuntu2204 ~]# ss -ntlp | grep 9000\nLISTEN   0   100   *:9000           *:*         users:((&quot;java&quot;,pid=26333,fd=155))\n\n# 访问下面链接地址\nhttp://192.168.80.150:9000\n</code></pre>\n<h4 id=\"访问-Cerebro-页面\"><a href=\"#访问-Cerebro-页面\" class=\"headerlink\" title=\"访问 Cerebro 页面\"></a>访问 Cerebro 页面</h4><p>在 <code>Node address</code> 输入框中输入任意 ES 集群节点的地址：<code>http://192.168.80.151:9200</code></p>\n<h2 id=\"4、ES-集群节点类型\"><a href=\"#4、ES-集群节点类型\" class=\"headerlink\" title=\"4、ES 集群节点类型\"></a>4、ES 集群节点类型</h2><p>ES 集群中节点类型介绍：</p>\n<ul>\n<li>Master</li>\n<li>Data</li>\n<li>Ingest</li>\n<li>Coordinating</li>\n</ul>\n<h3 id=\"4-1-Cluster-State\"><a href=\"#4-1-Cluster-State\" class=\"headerlink\" title=\"4.1 Cluster State\"></a>4.1 Cluster State</h3><p><code>Cluster State</code> 是用来存储 Elasticsearch 集群相关的元数据信息。它存储在每个节点上，主要包含以下信息：</p>\n<ul>\n<li>节点信息：这部分信息包括节点名称或节点的IP、节点的 IP 地址或端口等。</li>\n<li>索引元数据：这部分信息包括索引的名称、索引的配置设置（如分片数量、副本数量等）以及字段类型和属性等。</li>\n</ul>\n<h3 id=\"4-2-Master-角色\"><a href=\"#4-2-Master-角色\" class=\"headerlink\" title=\"4.2 Master 角色\"></a>4.2 Master 角色</h3><ol>\n<li>Elasticsearch 集群中只能有一个处于激活状态的 Master 节点。Master 节点负责管理和控制整个集群的操作；</li>\n<li>Master 节点负责维护集群状态（Cluster State）。当集群状态发生变化（例如，新增或删除索引、修改索引设置等）时，Master 节点会将更新后的集群状态同步给其他节点，以保持整个集群的状态一致性。</li>\n<li>Master 节点是通过选举产生的。集群中的节点可以设置 <code>node.master: true</code> 来允许它成为 Master 节点的候选者（默认为 true）。如果当前的 Master 节点失效或不可用时，集群会自动触发选举过程，从候选者中选出一个新的 Master 节点。</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>版本</th>\n<th>角色配置</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>7.X 版本</td>\n<td>Master 角色: <br> <code>node.master: true</code> <br> <code>node.data: false</code> <br> Data 角色: <br> <code>node.master: false</code> <br> <code>node.data: true</code> <br> Coordinating 角色: <br> <code>node.master: false</code> <br> <code>node.data: false</code></td>\n</tr>\n<tr>\n<td>8.X 版本</td>\n<td>Master 角色: <br> <code>node.roles: [&quot;master&quot;,&quot;data&quot;]</code> (既当 master, 又当 data) <br> Data 角色: <br> <code>node.roles: [&quot;data&quot;]</code> <br> Coordinating 角色: <br> <code>node.roles: []</code></td>\n</tr>\n</tbody></table>\n<h3 id=\"4-3-Data-角色\"><a href=\"#4-3-Data-角色\" class=\"headerlink\" title=\"4.3 Data 角色\"></a>4.3 Data 角色</h3><p>Data 节点是 Elasticsearch 集群中负责存储数据的节点。默认情况下，集群中的所有节点都是 Data 类型。</p>\n<ol>\n<li>可以通过设置 <code>node.data: true</code>（默认为 true）来保持节点作为 Data 节点。</li>\n<li>当创建索引后，索引中的数据会被存储在一个或多个 Data 节点上。这些能够存储索引数据的节点被称为 Data 节点。Data 节点负责处理数据查询、聚合和搜索等操作，它们直接影响整个集群的性能和存储能力。</li>\n</ol>\n<p>通过合理分配和管理 Data 节点，可以提高 Elasticsearch 集群的数据处理能力、查询性能和存储容量。在实际应用中，需要根据业务需求和硬件资源来调整 Data 节点的数量和配置。</p>\n<h3 id=\"4-4-Ingest-角色\"><a href=\"#4-4-Ingest-角色\" class=\"headerlink\" title=\"4.4 Ingest 角色\"></a>4.4 Ingest 角色</h3><p>Ingest 节点是 Elasticsearch 集群中负责预处理文档的过程，它允许文档在被写入到 Elasticsearch 之前，对其进行处理、清洗、或转换。</p>\n<ol>\n<li>假设你有一个包含日志数据的 JSON 文档，其中包含一个时间戳字段，但格式不符合标准。我们就可以在文档被写入之前，使用 date 处理器来转换时间戳字段的格式。</li>\n<li><code>node.ingest: true</code> 表示该节点可以对文档进行预处理操作。如果你希望某个节点不处理 Ingest 任务，可以设置为 false。</li>\n</ol>\n<h3 id=\"4-5-Coordinating-角色\"><a href=\"#4-5-Coordinating-角色\" class=\"headerlink\" title=\"4.5 Coordinating 角色\"></a>4.5 Coordinating 角色</h3><p>处理请求的节点被称为 Coordinating 节点。Coordinating 节点是 Elasticsearch 集群中所有节点的默认角色，无法取消。</p>\n<ol>\n<li>Coordinating 节点主要负责将请求路由到正确的节点。例如，创建索引的请求会被 Coordinating 节点路由到 Master 节点进行处理，而数据查询或写入的请求会被路由到相应的 Data 节点上。</li>\n<li>当一个节点同时设置 <code>node.master：false</code>、<code>node.data：false</code> 时，该节点仅充当 Coordinating 路由节点的角色。</li>\n</ol>\n<h3 id=\"4-6-角色设定示例\"><a href=\"#4-6-角色设定示例\" class=\"headerlink\" title=\"4.6 角色设定示例\"></a>4.6 角色设定示例</h3><ol>\n<li>如果希望节点只作为主节点<pre><code class=\"language-yaml\"># ES7.X\nnode.master: true\nnode.data: false\n\n# ES8.X\nnode.roles: [&quot;master&quot;, &quot;ingest&quot;]    # 只做 master, 不当 data\n</code></pre>\n</li>\n<li>如果希望节点只作为数据节点<pre><code class=\"language-yaml\"># ES7.X\nnode.master: false\nnode.data: true\n\n# ES8.X\nnode.roles: [&quot;data&quot;, &quot;ingest&quot;]    # 只当 data, 不做 master\n</code></pre>\n</li>\n<li>如果希望节点同时担任数据节点和主节点<pre><code class=\"language-yaml\"># ES7.X\nnode.master: true\nnode.data: true\n\n# ES8.X\nnode.roles: [&quot;master&quot;, &quot;data&quot;, &quot;ingest&quot;]    # 同时担任 master data\n</code></pre>\n</li>\n<li>如果希望节点不担任任何特定角色（不推荐）<pre><code class=\"language-yaml\"># ES7.X\nnode.master: false\nnode.data: false\n\n# ES8.X\nnode.roles: []    # 不担任任何角色\n</code></pre>\n</li>\n</ol>\n<h3 id=\"5-案例演示\"><a href=\"#5-案例演示\" class=\"headerlink\" title=\"5.案例演示\"></a>5.案例演示</h3><pre><code class=\"language-bash\"># 修改 ES 配置\nroot@es-node1: vim /etc/elasticsearch/elasticsearch.yml\nnode.roles: [&quot;data&quot;, &quot;ingest&quot;]    # 不做 master 节点 (默认每个节点都存在: master data ingest)\n\n# 重启 ES 服务\nroot@es-node1: systemctl restart elasticsearch\n</code></pre>\n<h2 id=\"5、ES-集群分片\"><a href=\"#5、ES-集群分片\" class=\"headerlink\" title=\"5、ES 集群分片\"></a>5、ES 集群分片</h2><h3 id=\"5-1-什么是分片\"><a href=\"#5-1-什么是分片\" class=\"headerlink\" title=\"5.1 什么是分片\"></a>5.1 什么是分片</h3><p>分片是处理和存储 PB 级别数据的基础。在 Elasticsearch 中，分片是一种<strong>数据分区机制</strong>，它允许将一份完整的数据分散存储到集群的多个不同服务器上。而每个分片只是索引的一个部分，这使得它们可以独立进行存储和查询。</p>\n<p>在 Elasticsearch 中，分片又被分为了两种类型：</p>\n<ol>\n<li><strong>主分片</strong>：主要负责存储数据。创建后主分片的数量是固定的（不允许修改）。</li>\n<li><strong>副本分片</strong>：每个主分片可以配置一个或多个副本分片，以增强数据的容错能力。副本分片从对应的主分片同步数据，确保在主分片出现问题时仍能提供服务。</li>\n</ol>\n<h3 id=\"5-2-什么是副本分片\"><a href=\"#5-2-什么是副本分片\" class=\"headerlink\" title=\"5.2 什么是副本分片\"></a>5.2 什么是副本分片</h3><p>副本分片主要用于提高数据的可用性，这样即使某个节点发生故障，系统依然可以自动从其他节点上的副本分片中恢复，并继续提供数据访问服务。</p>\n<p>如下图所示，node2 上是 oldxu_index 索引的一个完整副本数据。</p>\n<h3 id=\"5-3-ES-集群如何增大容量\"><a href=\"#5-3-ES-集群如何增大容量\" class=\"headerlink\" title=\"5.3 ES 集群如何增大容量\"></a>5.3 ES 集群如何增大容量</h3><ol>\n<li>如下 3 个节点的 ES 集群，创建了一个 oldxu_index 索引，同时指定了 3 个分片，和 1 个副本<pre><code class=\"language-bash\"># 创建索引, 设定主分片和副本分片\nPUT /oldxu_index\n&#123;\n    &quot;settings&quot;: &#123;\n    &quot;index&quot;: &#123;\n        &quot;number_of_shards&quot;: 3,    # 主分片\n        &quot;number_of_replicas&quot;: 1   # 副本分配\n    &#125;\n&#125;\n&#125;\n\n# 动态修改副本分片\nPUT /oldxu_index/_settings\n&#123;\n    &quot;number_of_replicas&quot;: 2    # 三节点,三分片. 因此最多只需要两副本就完全够了.\n&#125;\n</code></pre>\n</li>\n</ol>\n<p><strong>问题</strong>：目前一共有 3 个 ES 节点，如果此时增加一个新节点 是否能提高 oldxu_index 索引数据容量？<br><strong>答案</strong>：不能，因为 oldxu_index 只有 3 个分片，已经分布在 3 台节点上，那么新增的第四个节点对于 oldxu_index 而言是无法使用到的。所以也无法带来数据容量的提升。</p>\n<h3 id=\"5-4-ES-集群如何增加读性能\"><a href=\"#5-4-ES-集群如何增加读性能\" class=\"headerlink\" title=\"5.4 ES 集群如何增加读性能\"></a>5.4 ES 集群如何增加读性能</h3><p><strong>问题</strong>：目前一共有 3 个 ES 节点，如果增加副本数是否能提高 oldxu_index 索引的读性能？<br><strong>答案</strong>：不能，因为新增的副本还是会分布在这 node1、node2、node3 这三个节点上的，还是使用了相同的资源，也就意味着有读请求来时，这些请求还是会分配到 node1、node2、node3 上进行处理、也就意味着，还是利用了相同的硬件资源，所以不会提升读性能。</p>\n<p><strong>问题</strong>：如果需要增加读吞吐量性能，应该怎么来做？<br><strong>答案</strong>：增加读吞吐量还是需要添加节点，比如在增加三个节点 node4、node5、node6 那么将原来的 R0、R1、R2 分别迁移至新增的三个节点上，当有读请求来时会被分配 node4、node5、node6，也就意味着有新的 CPU、内存、IO，这样就不会在占用 node1、node2、node3 的硬件资源，那么这个时候读吞吐量才会得到真正的提升。</p>\n<h3 id=\"5-5-ES-副本与分片总结\"><a href=\"#5-5-ES-副本与分片总结\" class=\"headerlink\" title=\"5.5 ES 副本与分片总结\"></a>5.5 ES 副本与分片总结</h3><p>分片数和副本的设定非常重要，需要在集群部署前进行仔细规划：</p>\n<ol>\n<li><strong>分片过小</strong>：可能导致在后续需要水平扩容时无法通过增加节点来实现，因为数据已经在现有节点上达到了分布的极限。</li>\n<li><strong>分片过大</strong>：可能会导致单个节点上分布过多的分片，从而造成资源的浪费。此外，过多的分片也会影响 ES 的查询性能。</li>\n</ol>\n<h2 id=\"6、ES-集群故障转移\"><a href=\"#6、ES-集群故障转移\" class=\"headerlink\" title=\"6、ES 集群故障转移\"></a>6、ES 集群故障转移</h2><h3 id=\"6-1-什么是故障转移\"><a href=\"#6-1-什么是故障转移\" class=\"headerlink\" title=\"6.1 什么是故障转移\"></a>6.1 什么是故障转移</h3><p>所谓故障转移指的是，当集群中有节点发生故障时，这个集群是如何进行自动修复的。<br>ES 集群目前是由 3 个节点组成，此时集群状态是 green。</p>\n<h3 id=\"6-2-模拟节点故障案例\"><a href=\"#6-2-模拟节点故障案例\" class=\"headerlink\" title=\"6.2 模拟节点故障案例\"></a>6.2 模拟节点故障案例</h3><p>假设：node1 所在机器宕机导致服务终止，此时 ES 集群会如何处理；大体分为三个步骤：</p>\n<ol>\n<li><p><strong>重新选举</strong></p>\n</li>\n<li><p><strong>主分片调整</strong></p>\n</li>\n<li><p><strong>副本分片调整</strong></p>\n</li>\n<li><p><strong>重新选举阶段</strong>：node2 和 node3 发现 node1 无法响应；一段时间后会发起 master 选举。此时集群状态变为 Red 状态，假定选择 node2 为 master 节点；</p>\n</li>\n<li><p><strong>主分片调整阶段</strong>：node2 发现主分片 P0 未分配，将 node3 上的 R0 提升为主分片。此时所有的主分片都正常分配，集群状态变为 Yellow 状态；</p>\n</li>\n<li><p><strong>副本分片调整阶段</strong>：node2 将 P0 和 P1 主分片 重新生成新的副本分片 R0、R1。此时集群状态变为 Green；</p>\n</li>\n</ol>\n<h2 id=\"7、ES-文档路由原理\"><a href=\"#7、ES-文档路由原理\" class=\"headerlink\" title=\"7、ES 文档路由原理\"></a>7、ES 文档路由原理</h2><p>ES 文档分布式存储，当一个文档存储至 ES 集群时，存储的原理是什么样的？<br>如图所示，当我们想在一个集群保存文档时，Document1 是如何存储到分片 P1 的？选择 P1 的依据是什么？</p>\n<p>其实是有一个 <strong>文档到分片的映射算法</strong>，其目的是使所有文档均匀分布在所有的分片上。ES 既不使用随机算法，也不使用轮询算法，而是通过以下公式计算文档对应的分片：</p>\n<pre><code>shard = hash(routing) % number_of_primary_shards\n</code></pre>\n<ul>\n<li><code>hash</code>：算法保证将数据均匀分散在分片中</li>\n<li><code>routing</code>：是一个关键参数, 默认是文档 id, 也可以自定义。</li>\n<li><code>number_of_primary_shards</code>：主分片数（与主分片取模）</li>\n</ul>\n<p><strong>注意</strong>：该算法与主分片数相关，一旦确定后便不能更改主分片。因为一旦修改主分片数量，<code>shard</code> 的计算结果就会完全不一样，会导致无法定位到原有数据。</p>\n<p><strong>总结</strong>：ES 用 <code>hash(routing) % 主分片数</code> 来把文档分配到对应分片，确保分布均衡且可定位，因此主分片数不能改，否则找不到数据。</p>\n<h3 id=\"7-1-文档的创建流程\"><a href=\"#7-1-文档的创建流程\" class=\"headerlink\" title=\"7.1 文档的创建流程\"></a>7.1 文档的创建流程</h3><ol>\n<li>客户端发送请求：请求发送到任意节点（协调节点）。</li>\n<li>路由计算：协调节点 根据文档 ID 计算分片号：<code>shard = hash(document_id) % 主分片数量</code></li>\n<li>定位主分片：找到对应的主分片所在节点。</li>\n<li>主分片写入：写入内存 + translog，同时转发给副本分片。</li>\n<li>副本写入：副本分片完成相同写入操作。</li>\n<li>写入成功：所有副本确认后，最终返回成功响应给客户端。</li>\n</ol>\n<h3 id=\"7-2-文档的读取流程\"><a href=\"#7-2-文档的读取流程\" class=\"headerlink\" title=\"7.2 文档的读取流程\"></a>7.2 文档的读取流程</h3><ol>\n<li>客户端发起查询请求：发送到任意节点（协调节点）。</li>\n<li>协调节点分发请求到所有分片：查询是并行的，包括主分片和副本分片中任选一个。</li>\n<li>每个分片独立查询：每个分片返回自己的匹配结果（文档 + 分数等）。</li>\n<li>协调节点合并结果：统一排序、分页等，生成最终结果。</li>\n<li>返回客户端：查询结果发送回客户端。</li>\n</ol>\n<h3 id=\"7-3-文档批量创建的流程\"><a href=\"#7-3-文档批量创建的流程\" class=\"headerlink\" title=\"7.3 文档批量创建的流程\"></a>7.3 文档批量创建的流程</h3><p>（原文未补充内容）</p>\n<h3 id=\"7-4-文档批量读取的流程\"><a href=\"#7-4-文档批量读取的流程\" class=\"headerlink\" title=\"7.4 文档批量读取的流程\"></a>7.4 文档批量读取的流程</h3><p>（原文未补充内容）</p>\n<h2 id=\"8、ES-集群节点扩展\"><a href=\"#8、ES-集群节点扩展\" class=\"headerlink\" title=\"8、ES 集群节点扩展\"></a>8、ES 集群节点扩展</h2><h3 id=\"8-1-环境准备\"><a href=\"#8-1-环境准备\" class=\"headerlink\" title=\"8.1 环境准备\"></a>8.1 环境准备</h3><table>\n<thead>\n<tr>\n<th>系统版本</th>\n<th>主机名称</th>\n<th>IP 地址</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RockyLinux9</td>\n<td>es-node4</td>\n<td>192.168.80.154</td>\n</tr>\n<tr>\n<td>RockyLinux9</td>\n<td>es-node5</td>\n<td>192.168.80.155</td>\n</tr>\n</tbody></table>\n<h3 id=\"8-2-ES-扩展-Data-节点\"><a href=\"#8-2-ES-扩展-Data-节点\" class=\"headerlink\" title=\"8.2 ES 扩展 Data 节点\"></a>8.2 ES 扩展 Data 节点</h3><pre><code class=\"language-bash\">[root@node4 ~]# grep &quot;^[a-Z]&quot; /etc/elasticsearch/elasticsearch.yml\ncluster.name: es-cluster            # 集群名称\nnode.name: es-node4                 # 节点名称\nnode.roles: [&quot;data&quot;, &quot;ingest&quot;]      # ES8.x 配置 Data 节点, 不参与 Master 选举\nhttp.port: 9200\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 192.168.80.154        # 内网 IP 地址\n# bootstrap.memory_lock: true\ndiscovery.seed_hosts: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]\n\n# Enable security features\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# ES7.X 配置方式\n# node.data: true          # Data 节点\n# node.master: false       # 不参与 Master 选举\n\n[root@node4 ~]# systemctl restart elasticsearch\n</code></pre>\n<p>访问 CereBro 验证节点，路径：<code>Nodes &gt; Data 角色</code></p>\n<h3 id=\"8-3-ES-扩展-Coordinating-节点\"><a href=\"#8-3-ES-扩展-Coordinating-节点\" class=\"headerlink\" title=\"8.3 ES 扩展 Coordinating 节点\"></a>8.3 ES 扩展 Coordinating 节点</h3><pre><code class=\"language-bash\">[root@node5 ~]# grep &quot;^[a-Z]&quot; /etc/elasticsearch/elasticsearch.yml\ncluster.name: es-cluster                # 集群名称\nnode.name: es-node5                     # 节点名称\nnode.roles: []                          # ES8 配置 Coordinating 节点\nhttp.port: 9200\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\n# bootstrap.memory_lock: true\nnetwork.host: 192.168.80.155             # 内网 IP 地址\ndiscovery.seed_hosts: [&quot;192.168.80.151&quot;, &quot;192.168.80.152&quot;, &quot;192.168.80.153&quot;]\n# Enable security features\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false\n\n# ES7.X 配置方式\n# node.data: false     # 不参与 Data 节点\n# node.master: false   # 不参与 Master 选举\n\n[root@node5 ~]# systemctl restart elasticsearch\n</code></pre>\n<h3 id=\"8-4-节点扩展检查\"><a href=\"#8-4-节点扩展检查\" class=\"headerlink\" title=\"8.4 节点扩展检查\"></a>8.4 节点扩展检查</h3><p>通过 cerebro 检查集群扩展后的状态。<br>如果出现集群无法加入、或者加入集群被拒绝，尝试删除 <code>/var/lib/elasticsearch</code> 下的文件，然后重启 ES：</p>\n<pre><code class=\"language-bash\">[root@node5 ~]# rm -rf /var/lib/elasticsearch/*\n[root@node5 ~]# systemctl restart elasticsearch\n</code></pre>\n<p>如果将 data 节点修改为 Coordinating 节点，需要清理数据，否则无法启动：</p>\n<pre><code class=\"language-bash\"># repurpose 重新调整\n[root@node5 ~]# /usr/share/elasticsearch/bin/elasticsearch-node repurpose\n------------------------------------------------------------------------\nWARNING: Elasticsearch MUST be stopped before running this tool.\n\nFound 1 indices (1 shards and 1 index meta data) to clean up\nUse -v to see list of paths and indices affected\nNode is being re-purposed as no-master and no-data. Clean-up of index data will be performed.\nDo you want to proceed?\nConfirm [y/N] y\nNode successfully repurposed to no-master and no-data.\n</code></pre>\n<p>访问 CereBro 验证节点，路径：<code>Nodes &gt; Coordinating 角色</code></p>\n<h2 id=\"9、ES-集群调优建议\"><a href=\"#9、ES-集群调优建议\" class=\"headerlink\" title=\"9、ES 集群调优建议\"></a>9、ES 集群调优建议</h2><h3 id=\"9-1-内核参数优化\"><a href=\"#9-1-内核参数优化\" class=\"headerlink\" title=\"9.1 内核参数优化\"></a>9.1 内核参数优化</h3><ol>\n<li><strong>内核参数优化</strong><pre><code class=\"language-bash\">[root@node ~]# vim /etc/sysctl.conf\nfs.file-max=655360                        # 设定系统最大打开文件描述符数, 建议修改为 655360 或者更高;\nvm.max_map_count = 262144                 # 用于限制一个进程可以拥有的虚拟内存大小, 建议修改成 262144或更高。\nnet.core.somaxconn = 32768                # 设置系统允许的最大套接字监听（TCP SYN）队列长度；\nnet.ipv4.tcp_tw_reuse = 1                 # 启用 TCP TIME-WAIT 状态的套接字重用。\n# net.ipv4.ip_local_port_range = 1000 65535 # 设置本地端口范围, 即操作系统分配给本地套接字的端口号范围。\nnet.ipv4.tcp_max_tw_buckets = 400000      # 表示操作系统允许 TIME_WAIT 数量的最大值, 如果超过这个数字，TIME_WAIT套接字将立刻被清除\n\n[root@node ~]# sysctl -p\n</code></pre>\n</li>\n<li><strong>调整用户最大进程数（nproc），调整进程最大打开的文件描述符（nofile）</strong><pre><code class=\"language-bash\">[root@node ~]# rm -f /etc/security/limits.d/20-nproc.conf     # 删除默认 nproc 设定文件\n[root@node ~]# vim /etc/security/limits.conf\n*                soft    core           unlimited\n*                hard    core           unlimited\n*                soft    nproc          1000000\n*                hard    nproc          1000000\n*                soft    nofile         1000000\n*                hard    nofile         1000000\n*                soft    memlock        32000\n*                hard    memlock        32000\n*                soft    msgqueue       8192000\n*                hard    msgqueue       8192000\n</code></pre>\n</li>\n</ol>\n<h3 id=\"9-2-配置参数优化\"><a href=\"#9-2-配置参数优化\" class=\"headerlink\" title=\"9.2 配置参数优化\"></a>9.2 配置参数优化</h3><pre><code class=\"language-bash\"># 1. 启用内存锁定, 避免 ES 使用 swap 交换分区, 频繁的交换, 会导致 IOPS 变高.\n[root@es-node ~]# vim /etc/elasticsearch/elasticsearch.yml\nbootstrap.memory_lock: true\n\n# 2. 当 ES 配置内存锁定后, 需要确保操作系统允许 Elasticsearch 进程锁定足够的内存.\n[root@es-node ~]# sed -i &#39;/\\[Service\\]/a LimitMEMLOCK=infinity&#39; /usr/lib/systemd/system/elasticsearch.service\n\n# 3. 重新启动 elasticSearch\n[root@es-node ~]# systemctl daemon-reload\n[root@es-node ~]# systemctl restart elasticsearch\n</code></pre>\n<h3 id=\"9-3-JVM-参数优化\"><a href=\"#9-3-JVM-参数优化\" class=\"headerlink\" title=\"9.3 JVM 参数优化\"></a>9.3 JVM 参数优化</h3><h4 id=\"9-3-1-基础原则\"><a href=\"#9-3-1-基础原则\" class=\"headerlink\" title=\"9.3.1 基础原则\"></a>9.3.1 基础原则</h4><p>要估算 JVM 内存配置，主要看两点：</p>\n<ul>\n<li>要存多少数据</li>\n<li>有多少个节点（服务器）</li>\n</ul>\n<p>经验公式：<strong>1GB 内存 可以支持 48GB ~ 96GB 的数据量</strong>（通常按 1:48 来算最保险）<br>单个主分片大小最好控制在 <strong>30GB~50GB</strong></p>\n<h4 id=\"9-3-2-怎么估算内存和分片？\"><a href=\"#9-3-2-怎么估算内存和分片？\" class=\"headerlink\" title=\"9.3.2 怎么估算内存和分片？\"></a>9.3.2 怎么估算内存和分片？</h4><p><strong>第一步</strong>：算出实际需要存储的数据量</p>\n<pre><code>实际存储量 = 总数据量 × (副本数 + 1)    // 因为副本也要占空间\n</code></pre>\n<p>例如：总数据量 1TB + 副本数据 → 实际存储数据量 2TB</p>\n<p><strong>第二步</strong>：算每个节点要存多少数据</p>\n<pre><code>每节点存储 = 实际数据量 ÷ 节点数    // 再加上 20% 预留空间\n</code></pre>\n<p>示例：实际存储量 2TB &#x2F; 3 节点 + 20% 预留空间 → 每节点存储 850G</p>\n<p><strong>第三步</strong>：算每个节点需要多少内存</p>\n<pre><code>节点内存 ≈ 每节点存储量 ÷ 48（按1:48比例来算）\n</code></pre>\n<p>示例：每节点存储量 850G ÷ 48 → 节点内存 17 G</p>\n<p><strong>第四步</strong>：算分片数量（用于 ES）</p>\n<pre><code>主分片数量 = 总数据量 ÷ 30GB（建议一个分片控制在 30GB 左右）\n总分片数 = 主分片数 × (副本数 + 1)\n</code></pre>\n<p>示例：主分片数量 ≈ 33 → 总分片数 ≈ 66</p>\n<h4 id=\"9-3-3-两个简单例子\"><a href=\"#9-3-3-两个简单例子\" class=\"headerlink\" title=\"9.3.3 两个简单例子\"></a>9.3.3 两个简单例子</h4><p><strong>示例 1</strong>：1TB 数据，3 个节点，1 个副本</p>\n<ol>\n<li>实际要存：1TB × (1 + 1) &#x3D; 2 TB</li>\n<li>每节点：2TB ÷ 3 ≈ 700GB → 加 20% ≈ 850GB    &#x2F;&#x2F; 单节点实际存储</li>\n<li>内存需求：850GB ÷ 48 ≈ 17GB                &#x2F;&#x2F; 单节点建议内存 17 * 2 ≈ 34G</li>\n<li>JVM 配置：每个节点内存 17GB</li>\n<li>分片数量：1TB ÷ 30GB ≈ 33 个主分片</li>\n<li>总分片数 &#x3D; 33 × 2 &#x3D; 66 个</li>\n<li>单个索引分片数<br>a. 每日数据量 ÷ 30G &#x3D; （总数据量 ÷ 保留天数）÷ 30G<br>b. 100 ÷ 30G &#x3D; 3 分片            &#x2F;&#x2F; 每天 100G 日志<br>c. 1024 ÷ 30G &#x3D; 33 分片      &#x2F;&#x2F; 每天 1024G 日志</li>\n</ol>\n<p><strong>示例 2</strong>：2TB 数据，3 个节点，1 个副本</p>\n<ol>\n<li>实际要存：2TB × 2 &#x3D; 4TB</li>\n<li>每节点：4TB ÷ 3 ≈ 1.4TB → 加 20% ≈ 1.7TB            &#x2F;&#x2F; 单节点存储</li>\n<li>内存需求：1.7TB ÷ 48 ≈ 35GB → 超过建议上限（31GB）→ ⚠️ 不够用，得加节点！</li>\n</ol>\n<p>增加到 4 个节点</p>\n<ol>\n<li>每节点：4TB ÷ 4 &#x3D; 1TB → 加 20% ≈ 1.2TB</li>\n<li>内存需求：1.2TB ÷ 48 ≈ 25GB → 合理！</li>\n<li>分片数量：2TB ÷ 30GB &#x3D; 60 个主分片 → 总分片数 &#x3D; 60 × 2 &#x3D; 120个</li>\n</ol>\n<p><strong>结论</strong>：用 4 个节点，内存控制在 31GB 以内，刚刚好！</p>\n<h4 id=\"9-3-4-生产环境建议\"><a href=\"#9-3-4-生产环境建议\" class=\"headerlink\" title=\"9.3.4 生产环境建议\"></a>9.3.4 生产环境建议</h4><ul>\n<li>每天数据量：约 1TB</li>\n<li>机器配置：16 核，64GB 内存，6TB 磁盘（3 台 ECS）</li>\n<li>JVM 设置：最大和最小内存都设为 31GB</li>\n<li>最好不要超过 32GB（超过后 JVM 的内存优化会失效）</li>\n<li>ES 清理策略：只保留最近 1~2 周的数据，避免磁盘被撑爆。</li>\n</ul>\n<p>✅ <strong>结论</strong></p>\n<ul>\n<li>每天数据约 1TB，建议单分片控制在 30~50GB，1TB &#x2F; 30GB ≈ 每天 33 个主分片。</li>\n<li>实际存储量 &#x3D; 日志量 × (副本数 + 1)，估算内存按 1:48 比例。</li>\n<li>JVM 不建议超过 31GB，超过后 G1 GC 优化失效。</li>\n<li>索引清理建议使用 ILM，仅保留最近 1~2 周数据，避免磁盘撑满。</li>\n</ul>\n<hr>\n",
            "tags": [
                "ELK"
            ]
        }
    ]
}